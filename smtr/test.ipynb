{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "class '__torch__.torch_sparse.tensor.SparseTensor' already defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/huabei/work/smtr/test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/huabei/work/smtr/test.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfft\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/huabei/work/smtr/test.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/huabei/work/smtr/test.ipynb#ch0000000vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_sparse\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseTensor\n",
      "File \u001b[0;32m~/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=32'>33</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=33'>34</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDetected that PyTorch and torch_sparse were compiled with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=34'>35</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdifferent CUDA versions. PyTorch has CUDA version \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=35'>36</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mt_major\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mt_minor\u001b[39m}\u001b[39;00m\u001b[39m and torch_sparse has CUDA version \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=36'>37</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmajor\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mminor\u001b[39m}\u001b[39;00m\u001b[39m. Please reinstall the torch_sparse that \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=37'>38</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmatches your PyTorch install.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=39'>40</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseStorage  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseTensor  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtranspose\u001b[39;00m \u001b[39mimport\u001b[39;00m t  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/__init__.py?line=42'>43</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m narrow, __narrow_diag__  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_scatter\u001b[39;00m \u001b[39mimport\u001b[39;00m segment_csr\n\u001b[1;32m      <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_sparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseStorage, get_layout\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=11'>12</a>\u001b[0m \u001b[39m@torch\u001b[39;49m\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript\n\u001b[0;32m---> <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=12'>13</a>\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mSparseTensor\u001b[39;49;00m(\u001b[39mobject\u001b[39;49m):\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=13'>14</a>\u001b[0m     storage: SparseStorage\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=15'>16</a>\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=16'>17</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=17'>18</a>\u001b[0m         row: Optional[torch\u001b[39m.\u001b[39;49mTensor] \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=23'>24</a>\u001b[0m         trust_data: \u001b[39mbool\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch_sparse/tensor.py?line=24'>25</a>\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py:974\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m    <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=971'>972</a>\u001b[0m     \u001b[39mif\u001b[39;00m _rcb \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=972'>973</a>\u001b[0m         _rcb \u001b[39m=\u001b[39m _jit_internal\u001b[39m.\u001b[39mcreateResolutionCallbackFromFrame(_frames_up \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=973'>974</a>\u001b[0m     _compile_and_register_class(obj, _rcb, qualified_name)\n\u001b[1;32m    <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=974'>975</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m    <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=975'>976</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=976'>977</a>\u001b[0m     \u001b[39m# this is a decorated fn, and we need to the underlying fn and its rcb\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py:67\u001b[0m, in \u001b[0;36m_compile_and_register_class\u001b[0;34m(obj, rcb, qualified_name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=64'>65</a>\u001b[0m ast \u001b[39m=\u001b[39m get_jit_class_def(obj, obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=65'>66</a>\u001b[0m defaults \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mfrontend\u001b[39m.\u001b[39mget_default_args_for_class(obj)\n\u001b[0;32m---> <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=66'>67</a>\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_script_class_compile(qualified_name, ast, defaults, rcb)\n\u001b[1;32m     <a href='file:///home/huabei/anaconda3/envs/smtr/lib/python3.8/site-packages/torch/jit/_script.py?line=67'>68</a>\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39m_add_script_class(obj, qualified_name)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: class '__torch__.torch_sparse.tensor.SparseTensor' already defined."
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch.fft\n",
    "import pandas as pd\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = defaultdict(lambda: len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "for c in range(5):\n",
    "    for n in range(5):\n",
    "        print(c, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 4],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [1, 4],\n",
       "        [2, 0],\n",
       "        [2, 1],\n",
       "        [2, 2],\n",
       "        [2, 3],\n",
       "        [2, 4],\n",
       "        [3, 0],\n",
       "        [3, 1],\n",
       "        [3, 2],\n",
       "        [3, 3],\n",
       "        [3, 4],\n",
       "        [4, 0],\n",
       "        [4, 1],\n",
       "        [4, 2],\n",
       "        [4, 3],\n",
       "        [4, 4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([(c, n) for c in range(5) for n in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame({'i': range(5), 'i^2': [i**2 for i in range(5)]})\n",
    "d.shape[0]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a75462293d05fc3e00128f4985dd13fcf50f4f5144b1474848efbcac1f09cd24"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('smtr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
